{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-24T17:03:45.843862Z",
     "start_time": "2023-12-24T17:03:45.842239Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel,GPT2Tokenizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "model_name = \"gpt2-large\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T17:04:20.830229Z",
     "start_time": "2023-12-24T17:03:46.258460Z"
    }
   },
   "id": "4840f2a2874c757c"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "GPT2LMHeadModel(\n  (transformer): GPT2Model(\n    (wte): Embedding(50257, 1280)\n    (wpe): Embedding(1024, 1280)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0-35): 36 x GPT2Block(\n        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=1280, out_features=50257, bias=False)\n)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T17:04:20.864677Z",
     "start_time": "2023-12-24T17:04:20.812814Z"
    }
   },
   "id": "690c2304592c63f3"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 774030080\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of parameters:\", model.num_parameters())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T17:04:20.881115Z",
     "start_time": "2023-12-24T17:04:20.855027Z"
    }
   },
   "id": "98b1ab353ca2e6ad"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "def chat(input_text, max_length=100, temperature=0.7, top_k=50):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        max_length=max_length,\n",
    "        temperature=temperature,\n",
    "        top_k=top_k,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        do_sample=True\n",
    "    )\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return generated_text\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T17:55:53.014345Z",
     "start_time": "2023-12-24T17:55:52.944361Z"
    }
   },
   "id": "35188c8172dd958a"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def generate_text(prompt, max_length=100, temperature=0.7, top_k=50):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        max_length=max_length,\n",
    "        temperature=temperature,\n",
    "        top_k=top_k,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        do_sample=True\n",
    "    )\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return generated_text"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T17:04:20.881472Z",
     "start_time": "2023-12-24T17:04:20.856436Z"
    }
   },
   "id": "45801542dd6387c8"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Hi! I'm your chatbot. Type 'exit' to end the conversation.\n",
      "Bot: Hi how are you doing, my friend?\n",
      "\n",
      "The answer, I think, is that you're doing fine. You have a lot of friends, and you're not in your mother's shadow, so you're doing fine.\n",
      "\n",
      "A lot of people have told me, \"I just couldn't afford the price of the book, and I had to give it away to someone.\" And I'm proud that I gave away a bunch of books to strangers. I feel very good about that\n",
      "Bot: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "print(\"Bot: Hi! I'm your chatbot. Type 'exit' to end the conversation.\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    \n",
    "    if user_input.lower() == 'exit':\n",
    "        print(\"Bot: Goodbye!\")\n",
    "        break\n",
    "    \n",
    "    response = chat(user_input)\n",
    "    print(\"You: \",user_input)\n",
    "    print(\"Bot:\", response)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T17:57:04.611876Z",
     "start_time": "2023-12-24T17:56:14.310776Z"
    }
   },
   "id": "cdb9e0704523767e"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cities in US are San Fransico, New York, Boston, Chicago, Los Angeles, Philadelphia, Washington DC, and Miami.\n",
      "\n",
      "The cities in UK are Birmingham, London, Manchester, Newcastle, Sheffield, Glasgow, Cardiff, Leeds, Nottingham, Nottinghamshire, Nottingham, and Oxford.\n",
      "\n",
      "The cities in Canada are Toronto, Vancouver, Montreal, Calgary, Edmonton, Calgary, Edmonton, and Vancouver.\n",
      "\n",
      "The cities in Australia are Melbourne, Sydney, Canberra, Perth, Canberra, and Melbourne.\n",
      "\n",
      "The cities in Canada are Calgary, Edmonton, Vancouver, and Edmonton\n"
     ]
    }
   ],
   "source": [
    "prompt = \"The cities in US are San Fransico, New York\"\n",
    "generated_text = generate_text(prompt, max_length=120)\n",
    "\n",
    "# Print the generated text\n",
    "print(generated_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T17:05:16.978094Z",
     "start_time": "2023-12-24T17:04:47.866853Z"
    }
   },
   "id": "7fb6d0c7c716e995"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country,city;USA,New York;USA,Chicago;Canada,Toronto;UK,London;France,Paris;Germany,Berlin;Australia,Sydney;Japan,Tokyo;Mexico,Mexico City;Australia,Melbourne;Canada,Vancouver;Mexico,Mexico City;Australia,Melbourne;Canada,Vancouver;Mexico,Mexico City;Australia,Melbourne;Canada,Vancouver;Mexico,Mexico City;Australia,Melbourne;Canada,Vancouver;Mexico,Mexico City;Australia,Melbourne;Canada,Vancouver;Mexico,Mexico City\n"
     ]
    }
   ],
   "source": [
    "prompt = \"country,city;USA,New York;USA,Chicago;Canada,Toronto;UK,London;France,Paris;Germany,Berlin;Australia,Sydney;Japan,Tokyo;\"\n",
    "generated_text = generate_text(prompt, max_length=120)\n",
    "print(generated_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T17:25:53.343374Z",
     "start_time": "2023-12-24T17:25:26.657150Z"
    }
   },
   "id": "2416a4955fdb3e7b"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Node_ID]: 201 [Node_Name]: Etching_Module [Material_Cost]: 50000 [Assembly_Cost]: 2000, [Node_ID]: 202 [Node_Name]: Pressure_Control_Unit [Material_Cost]: 30000 [Assembly_Cost]: 1200, [Node_ID]: 203 [Node_Name]: Pressure_Sensor [Material_Cost]: 10000 [Assembly_Cost]: 10000, [Node_ID]: 204 [Node_Name]: PressureSensor_Sensor [Material_Cost]: 10000 [Assembly_Cost]: 10000, [Node_ID]: 205\n"
     ]
    }
   ],
   "source": [
    "prompt = \"[Node_ID]: 201 [Node_Name]: Etching_Module [Material_Cost]: 50000 [Assembly_Cost]: 2000, [Node_ID]: 202 [Node_Name]: Pressure_Control_Unit [Material_Cost]: 30000 [Assembly_Cost]: 1200,\"\n",
    "generated_text = generate_text(prompt, max_length=120)\n",
    "print(generated_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T17:50:37.248950Z",
     "start_time": "2023-12-24T17:50:10.449523Z"
    }
   },
   "id": "9e70aeda8681bf14"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "x = generated_text.split(';')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T17:26:32.107750Z",
     "start_time": "2023-12-24T17:26:32.101947Z"
    }
   },
   "id": "321395b29f2b31ec"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country,city\n",
      "USA,New York\n",
      "USA,Chicago\n",
      "Canada,Toronto\n",
      "UK,London\n",
      "France,Paris\n",
      "Germany,Berlin\n",
      "Australia,Sydney\n",
      "Japan,Tokyo\n",
      "Mexico,Mexico City\n",
      "Australia,Melbourne\n",
      "Canada,Vancouver\n",
      "Mexico,Mexico City\n",
      "Australia,Melbourne\n",
      "Canada,Vancouver\n",
      "Mexico,Mexico City\n",
      "Australia,Melbourne\n",
      "Canada,Vancouver\n",
      "Mexico,Mexico City\n",
      "Australia,Melbourne\n",
      "Canada,Vancouver\n",
      "Mexico,Mexico City\n",
      "Australia,Melbourne\n",
      "Canada,Vancouver\n",
      "Mexico,Mexico City\n"
     ]
    }
   ],
   "source": [
    "for i in x:\n",
    "    print(i)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T17:26:48.017244Z",
     "start_time": "2023-12-24T17:26:48.002320Z"
    }
   },
   "id": "3cd77f6e8ec6182c"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of India is located in the state of Uttar Pradesh, which is known for its rich culture and history. The city is also known for its beautiful temples and monuments.\n",
      "\n",
      "The city is also known for its beautiful temples and monuments. The\n"
     ]
    }
   ],
   "source": [
    "prompt = \"The capital of India is located in\"\n",
    "generated_text = generate_text(prompt, max_length=50)\n",
    "\n",
    "# Print the generated text\n",
    "print(generated_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T03:48:10.111543Z",
     "start_time": "2023-12-23T03:48:04.548746Z"
    }
   },
   "id": "11844a04712c3b7a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "interact_model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec2b7607dc13e8c5"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e350ec107bcc41ddaf650a261e40a66e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d94e19fd32c444be938d5e4df337ccd7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4afdb13d9aa34eba81d9719583158153"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "61dfa5088daf4803b105cb809e6bc0f5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c19fe5c45f7641ca91329d5d82c539c7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "992c7d3650f54d8a822353eb6045c298"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T03:40:02.231490Z",
     "start_time": "2023-12-23T03:33:03.620518Z"
    }
   },
   "id": "1c7b6a9cb606d289"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "60506624"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_parameters()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T03:41:38.641712Z",
     "start_time": "2023-12-23T03:41:38.635611Z"
    }
   },
   "id": "b072eedd8e4dd663"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "<bound method Module.eval of T5ForConditionalGeneration(\n  (shared): Embedding(32128, 512)\n  (encoder): T5Stack(\n    (embed_tokens): Embedding(32128, 512)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n              (relative_attention_bias): Embedding(32, 8)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-5): 5 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (decoder): T5Stack(\n    (embed_tokens): Embedding(32128, 512)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n              (relative_attention_bias): Embedding(32, 8)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-5): 5 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n)>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T03:43:13.832596Z",
     "start_time": "2023-12-23T03:43:13.822963Z"
    }
   },
   "id": "556779f07e7e747a"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def generate_text(prompt, max_length=100, temperature=0.1, top_k=50):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        max_length=max_length,\n",
    "        temperature=temperature,\n",
    "        top_k=top_k,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        do_sample=True\n",
    "    )\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return generated_text"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T03:45:08.462186Z",
     "start_time": "2023-12-23T03:45:08.457701Z"
    }
   },
   "id": "284ed0c2ce39866d"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pouss you sing me a poem\n"
     ]
    }
   ],
   "source": [
    "prompt = (\"Can you sing me a poem\")\n",
    "generated_text = generate_text(prompt, max_length=40)\n",
    "print(generated_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T03:46:21.468891Z",
     "start_time": "2023-12-23T03:46:21.334862Z"
    }
   },
   "id": "e0a6401c19790644"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2Config\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Load pre-trained GPT-2 model and tokenizer\n",
    "model_name = \"gpt2-large\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T14:52:46.634285Z",
     "start_time": "2023-12-24T14:52:29.323432Z"
    }
   },
   "id": "fc5705c795cb4c1f"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "# Load your tabular data (replace with your own)\n",
    "data = {\n",
    "    \"Name\": [\"John\", \"Alice\", \"Bob\"],\n",
    "    \"Age\": [25, 30, 22],\n",
    "    \"City\": [\"New York\", \"San Francisco\", \"Los Angeles\"],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert tabular data to text\n",
    "text_data = []\n",
    "for index, row in df.iterrows():\n",
    "    row_text = \" \".join([f\"[{col}]: {str(row[col])}\" for col in df.columns])\n",
    "    text_data.append(row_text)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T14:52:55.663476Z",
     "start_time": "2023-12-24T14:52:55.661248Z"
    }
   },
   "id": "830c4e5589e5a405"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "['[Name]: John [Age]: 25 [City]: New York',\n '[Name]: Alice [Age]: 30 [City]: San Francisco',\n '[Name]: Bob [Age]: 22 [City]: Los Angeles']"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T14:52:56.178419Z",
     "start_time": "2023-12-24T14:52:56.173192Z"
    }
   },
   "id": "60633524b5ef71d8"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "tokenized_data = [tokenizer.encode(row, return_tensors=\"pt\") for row in text_data]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T14:53:45.853563Z",
     "start_time": "2023-12-24T14:53:45.845338Z"
    }
   },
   "id": "5da5ee33fbbe576a"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "[tensor([[   58,  5376,  5974,  1757,   685, 23396,  5974,  1679,   685, 14941,\n           5974,   968,  1971]]),\n tensor([[   58,  5376,  5974, 14862,   685, 23396,  5974,  1542,   685, 14941,\n           5974,  2986,  6033]]),\n tensor([[   58,  5376,  5974,  5811,   685, 23396,  5974,  2534,   685, 14941,\n           5974,  5401,  5652]])]"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T14:53:46.278910Z",
     "start_time": "2023-12-24T14:53:46.274073Z"
    }
   },
   "id": "9c3b3f49ece9f72f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Convert tabular data to text\n",
    "text_data = []\n",
    "for index, row in df.iterrows():\n",
    "    row_text = \" \".join([f\"[{col}]: {str(row[col])}\" for col in df.columns])\n",
    "    text_data.append(row_text)\n",
    "\n",
    "# Tokenize the tabular data\n",
    "tokenized_data = [tokenizer.encode(row, return_tensors=\"pt\") for row in text_data]\n",
    "\n",
    "# DataLoader for training\n",
    "dataloader = DataLoader(tokenized_data, batch_size=2, shuffle=True)\n",
    "\n",
    "# Example fine-tuning function\n",
    "def fine_tune_gpt2(model_name, dataloader, output_dir):\n",
    "    # Load GPT-2 model\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "    \n",
    "    # Fine-tuning setup...\n",
    "    # (You can use the provided fine-tuning function or customize it based on your specific needs)\n",
    "\n",
    "    # Example training loop\n",
    "    for epoch in range(5):\n",
    "        for inputs in dataloader:\n",
    "            model.train()\n",
    "            # Your training code here...\n",
    "            # (This is where you update the model with your training data)\n",
    "\n",
    "    # Save the fine-tuned model\n",
    "    model.save_pretrained(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "# Example usage\n",
    "fine_tune_gpt2(\"gpt2-large\", dataloader, \"downloads\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-12-24T11:51:31.121107Z"
    }
   },
   "id": "6fd533397229e012"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m tokenized_data \u001B[38;5;241m=\u001B[39m [tokenizer\u001B[38;5;241m.\u001B[39mencode(row, return_tensors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m row \u001B[38;5;129;01min\u001B[39;00m \u001B[43mtext_data\u001B[49m]\n",
      "\u001B[0;31mNameError\u001B[0m: name 'text_data' is not defined"
     ]
    }
   ],
   "source": [
    "tokenized_data = [tokenizer.encode(row, return_tensors=\"pt\") for row in text_data]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T14:51:56.988577Z",
     "start_time": "2023-12-24T14:51:56.770426Z"
    }
   },
   "id": "d3cfbf8de0eb7a7c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c7531b047f13b4ef"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
