{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A/B Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "In modern data analytics, deciding whether two numerical samples come from the same\n",
    "underlying distribution is called A/B testing. The name refers to the labels of the two\n",
    "samples, A and B."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Smokers and Nonsmokers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset \"baby.csv\" contains the following variables for 1,174 mother-baby pairs: \n",
    "the baby's birth weight in ounces, \n",
    "the number of gestational days, \n",
    "the mother's age in completed years,\n",
    "the mother's height in inches, \n",
    "pregnancy weight in pounds, and \n",
    "whether or not the mother smoked during pregnancy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One of the aims of the study was to see whether maternal smoking was associated with birth weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Start by selecting just Birth Weight and Maternal Smoker. There are 715 nonsmokers among the women in the sample, and 459 smokers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T13:17:59.326654Z",
     "start_time": "2023-11-02T13:17:59.319308Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plots\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T13:17:59.331507Z",
     "start_time": "2023-11-02T13:17:59.326780Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T13:18:01.294487Z",
     "start_time": "2023-11-02T13:17:59.329598Z"
    }
   },
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mHTTPError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m baby \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhttps://github.com/data-8/textbook/raw/gh-pages/data/baby.csv\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/pandas/util/_decorators.py:211\u001B[0m, in \u001B[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    209\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    210\u001B[0m         kwargs[new_arg_name] \u001B[38;5;241m=\u001B[39m new_arg_value\n\u001B[0;32m--> 211\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/pandas/util/_decorators.py:331\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    325\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m num_allow_args:\n\u001B[1;32m    326\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    327\u001B[0m         msg\u001B[38;5;241m.\u001B[39mformat(arguments\u001B[38;5;241m=\u001B[39m_format_argument_list(allow_args)),\n\u001B[1;32m    328\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[1;32m    329\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mfind_stack_level(),\n\u001B[1;32m    330\u001B[0m     )\n\u001B[0;32m--> 331\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/pandas/io/parsers/readers.py:950\u001B[0m, in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[1;32m    935\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[1;32m    936\u001B[0m     dialect,\n\u001B[1;32m    937\u001B[0m     delimiter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    946\u001B[0m     defaults\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdelimiter\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m},\n\u001B[1;32m    947\u001B[0m )\n\u001B[1;32m    948\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[0;32m--> 950\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001B[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/pandas/io/parsers/readers.py:605\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    602\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[1;32m    604\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[0;32m--> 605\u001B[0m parser \u001B[38;5;241m=\u001B[39m TextFileReader(filepath_or_buffer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[1;32m    607\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[1;32m    608\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1442\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m   1439\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m   1441\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1442\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_engine(f, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mengine)\n",
      "File \u001B[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1735\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[0;34m(self, f, engine)\u001B[0m\n\u001B[1;32m   1733\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[1;32m   1734\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m-> 1735\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m get_handle(\n\u001B[1;32m   1736\u001B[0m     f,\n\u001B[1;32m   1737\u001B[0m     mode,\n\u001B[1;32m   1738\u001B[0m     encoding\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[1;32m   1739\u001B[0m     compression\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcompression\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[1;32m   1740\u001B[0m     memory_map\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmemory_map\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m),\n\u001B[1;32m   1741\u001B[0m     is_text\u001B[38;5;241m=\u001B[39mis_text,\n\u001B[1;32m   1742\u001B[0m     errors\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mencoding_errors\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstrict\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m   1743\u001B[0m     storage_options\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstorage_options\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[1;32m   1744\u001B[0m )\n\u001B[1;32m   1745\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1746\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/pandas/io/common.py:713\u001B[0m, in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    710\u001B[0m     codecs\u001B[38;5;241m.\u001B[39mlookup_error(errors)\n\u001B[1;32m    712\u001B[0m \u001B[38;5;66;03m# open URLs\u001B[39;00m\n\u001B[0;32m--> 713\u001B[0m ioargs \u001B[38;5;241m=\u001B[39m _get_filepath_or_buffer(\n\u001B[1;32m    714\u001B[0m     path_or_buf,\n\u001B[1;32m    715\u001B[0m     encoding\u001B[38;5;241m=\u001B[39mencoding,\n\u001B[1;32m    716\u001B[0m     compression\u001B[38;5;241m=\u001B[39mcompression,\n\u001B[1;32m    717\u001B[0m     mode\u001B[38;5;241m=\u001B[39mmode,\n\u001B[1;32m    718\u001B[0m     storage_options\u001B[38;5;241m=\u001B[39mstorage_options,\n\u001B[1;32m    719\u001B[0m )\n\u001B[1;32m    721\u001B[0m handle \u001B[38;5;241m=\u001B[39m ioargs\u001B[38;5;241m.\u001B[39mfilepath_or_buffer\n\u001B[1;32m    722\u001B[0m handles: \u001B[38;5;28mlist\u001B[39m[BaseBuffer]\n",
      "File \u001B[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/pandas/io/common.py:363\u001B[0m, in \u001B[0;36m_get_filepath_or_buffer\u001B[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001B[0m\n\u001B[1;32m    361\u001B[0m \u001B[38;5;66;03m# assuming storage_options is to be interpreted as headers\u001B[39;00m\n\u001B[1;32m    362\u001B[0m req_info \u001B[38;5;241m=\u001B[39m urllib\u001B[38;5;241m.\u001B[39mrequest\u001B[38;5;241m.\u001B[39mRequest(filepath_or_buffer, headers\u001B[38;5;241m=\u001B[39mstorage_options)\n\u001B[0;32m--> 363\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m urlopen(req_info) \u001B[38;5;28;01mas\u001B[39;00m req:\n\u001B[1;32m    364\u001B[0m     content_encoding \u001B[38;5;241m=\u001B[39m req\u001B[38;5;241m.\u001B[39mheaders\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mContent-Encoding\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m    365\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m content_encoding \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgzip\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    366\u001B[0m         \u001B[38;5;66;03m# Override compression based on Content-Encoding header\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/pandas/io/common.py:265\u001B[0m, in \u001B[0;36murlopen\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    259\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    260\u001B[0m \u001B[38;5;124;03mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001B[39;00m\n\u001B[1;32m    261\u001B[0m \u001B[38;5;124;03mthe stdlib.\u001B[39;00m\n\u001B[1;32m    262\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    263\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01murllib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrequest\u001B[39;00m\n\u001B[0;32m--> 265\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m urllib\u001B[38;5;241m.\u001B[39mrequest\u001B[38;5;241m.\u001B[39murlopen(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/envs/tf/lib/python3.11/urllib/request.py:216\u001B[0m, in \u001B[0;36murlopen\u001B[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001B[0m\n\u001B[1;32m    214\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    215\u001B[0m     opener \u001B[38;5;241m=\u001B[39m _opener\n\u001B[0;32m--> 216\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m opener\u001B[38;5;241m.\u001B[39mopen(url, data, timeout)\n",
      "File \u001B[0;32m~/anaconda3/envs/tf/lib/python3.11/urllib/request.py:525\u001B[0m, in \u001B[0;36mOpenerDirector.open\u001B[0;34m(self, fullurl, data, timeout)\u001B[0m\n\u001B[1;32m    523\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m processor \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_response\u001B[38;5;241m.\u001B[39mget(protocol, []):\n\u001B[1;32m    524\u001B[0m     meth \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(processor, meth_name)\n\u001B[0;32m--> 525\u001B[0m     response \u001B[38;5;241m=\u001B[39m meth(req, response)\n\u001B[1;32m    527\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m response\n",
      "File \u001B[0;32m~/anaconda3/envs/tf/lib/python3.11/urllib/request.py:634\u001B[0m, in \u001B[0;36mHTTPErrorProcessor.http_response\u001B[0;34m(self, request, response)\u001B[0m\n\u001B[1;32m    631\u001B[0m \u001B[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001B[39;00m\n\u001B[1;32m    632\u001B[0m \u001B[38;5;66;03m# request was successfully received, understood, and accepted.\u001B[39;00m\n\u001B[1;32m    633\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;241m200\u001B[39m \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m code \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m300\u001B[39m):\n\u001B[0;32m--> 634\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparent\u001B[38;5;241m.\u001B[39merror(\n\u001B[1;32m    635\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhttp\u001B[39m\u001B[38;5;124m'\u001B[39m, request, response, code, msg, hdrs)\n\u001B[1;32m    637\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m response\n",
      "File \u001B[0;32m~/anaconda3/envs/tf/lib/python3.11/urllib/request.py:563\u001B[0m, in \u001B[0;36mOpenerDirector.error\u001B[0;34m(self, proto, *args)\u001B[0m\n\u001B[1;32m    561\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m http_err:\n\u001B[1;32m    562\u001B[0m     args \u001B[38;5;241m=\u001B[39m (\u001B[38;5;28mdict\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdefault\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhttp_error_default\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;241m+\u001B[39m orig_args\n\u001B[0;32m--> 563\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_chain(\u001B[38;5;241m*\u001B[39margs)\n",
      "File \u001B[0;32m~/anaconda3/envs/tf/lib/python3.11/urllib/request.py:496\u001B[0m, in \u001B[0;36mOpenerDirector._call_chain\u001B[0;34m(self, chain, kind, meth_name, *args)\u001B[0m\n\u001B[1;32m    494\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m handler \u001B[38;5;129;01min\u001B[39;00m handlers:\n\u001B[1;32m    495\u001B[0m     func \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(handler, meth_name)\n\u001B[0;32m--> 496\u001B[0m     result \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs)\n\u001B[1;32m    497\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m result \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    498\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/anaconda3/envs/tf/lib/python3.11/urllib/request.py:643\u001B[0m, in \u001B[0;36mHTTPDefaultErrorHandler.http_error_default\u001B[0;34m(self, req, fp, code, msg, hdrs)\u001B[0m\n\u001B[1;32m    642\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mhttp_error_default\u001B[39m(\u001B[38;5;28mself\u001B[39m, req, fp, code, msg, hdrs):\n\u001B[0;32m--> 643\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m HTTPError(req\u001B[38;5;241m.\u001B[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001B[0;31mHTTPError\u001B[0m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "baby = pd.read_csv('https://github.com/data-8/textbook/raw/gh-pages/data/baby.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-02T13:18:01.295927Z"
    }
   },
   "outputs": [],
   "source": [
    "# or from 'https://raw.githubusercontent.com/data-8/textbook/gh-pages/data/baby.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-02T13:18:01.296620Z"
    }
   },
   "outputs": [],
   "source": [
    "baby.to_csv('E:/2020/DS/19AI611/python_data_csv/baby.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-02T13:18:01.297526Z"
    }
   },
   "outputs": [],
   "source": [
    "baby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-02T13:18:01.298485Z"
    }
   },
   "outputs": [],
   "source": [
    "smoking_and_birthweight = baby[['Maternal Smoker', 'Birth Weight']]\n",
    "smoking_and_birthweight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-02T13:18:01.299390Z"
    }
   },
   "outputs": [],
   "source": [
    "smoking_and_birthweight['Maternal Smoker'] == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-02T13:18:01.300195Z"
    }
   },
   "outputs": [],
   "source": [
    "smoker = smoking_and_birthweight['Birth Weight'] [smoking_and_birthweight['Maternal Smoker'] == True]\n",
    "smoker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-02T13:18:01.300992Z"
    }
   },
   "outputs": [],
   "source": [
    "non_smoker = smoking_and_birthweight['Birth Weight'] [smoking_and_birthweight['Maternal Smoker'] == False]\n",
    "non_smoker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-02T13:18:01.301812Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-02T13:18:01.302612Z"
    }
   },
   "outputs": [],
   "source": [
    "smoking_and_birthweight.hist(by ='Maternal Smoker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-02T13:18:01.303583Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "smoker.hist(histtype='stepfilled', alpha=.5, bins=20)   # default number of bins = 10\n",
    "non_smoker.hist(histtype='stepfilled', alpha=.5, color=sns.desaturate(\"indianred\", .75), bins=10)\n",
    "plt.xlabel('Women',fontsize=15)\n",
    "plt.ylabel('Baby weight',fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of the weights of the babies born to mothers who smoked appears to be\n",
    "shifted slightly to the left of the distribution corresponding to non-smoking mothers. The\n",
    "weights of the babies of the mothers who smoked seem lower, on average than the weights\n",
    "of the babies of the non-smokers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Hypotheses\n",
    "We can try to answer this question by a test of hypotheses. The chance model that we will\n",
    "test says that there is no underlying difference; the distributions in the samples are different\n",
    "just due to chance. Formally, this is the null hypothesis.\n",
    "Null hypothesis: In the population, the distribution of birth weights of babies is the same for\n",
    "mothers who don't smoke as for mothers who do. The difference in the sample is due to chance.\n",
    "Alternative hypothesis: In the population, the babies of the mothers who smoke have a\n",
    "lower birth weight, on average, than the babies of the non-smokers. \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Statistic\n",
    "The alternative hypothesis compares the average birth weights of the two groups and says\n",
    "that the average for the mothers who smoke is smaller. Therefore it is reasonable for us to\n",
    "use the difference between the two group means as our statistic.\n",
    "\n",
    "We will do the subtraction in the order \"average weight of the smoking group - average\n",
    "weight of the non-smoking group\". Small values (that is, large negative values) of this\n",
    "statistic will favor the alternative hypothesis\n",
    "\n",
    "The observed value of the test statistic is about -9.3 ounces.\n",
    "means_table = smoking_and_birthweight.group('Maternal Smoker',np.average)\n",
    "means_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-02T13:18:01.304435Z"
    }
   },
   "outputs": [],
   "source": [
    "means_table = smoking_and_birthweight.groupby('Maternal Smoker').mean()\n",
    "type(means_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-02T13:18:01.305419Z"
    }
   },
   "outputs": [],
   "source": [
    "means_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-02T13:18:01.306347Z"
    }
   },
   "outputs": [],
   "source": [
    "observed_difference = means_table['Birth Weight'][1] - means_table['Birth Weight'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting the Statistic Under the Null Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see how the statistic should vary under the null hypothesis, we have to figure out how to\n",
    "simulate the statistic under that hypothesis. A clever method based on random permutations\n",
    "does just that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random permutation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there were no difference between the two distributions in the underlying population, then whether a birth weight has the label True or False with respect to maternal smoking should make no difference to the average. The idea, then, is to shuffle all the birth weights randomly among the mothers. This is called random permutation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the difference of the two new group means: the mean of the shuffled weights assigned to the smokers and the mean of the shuffled weights assigned to the non-smokers. This is a simulated value of the test statistic under the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-02T13:18:01.307279Z"
    }
   },
   "outputs": [],
   "source": [
    "smoking_and_birthweight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 1,174 rows in the table. To shuffle all the birthweights, we will draw a random\n",
    "sample of 1,174 rows without replacement. Then the sample will include all the rows of the\n",
    "table, in random order.\n",
    "We can use the method sample with the optional replace=False argument.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-02T13:18:01.308430Z"
    }
   },
   "outputs": [],
   "source": [
    "shuffled = smoking_and_birthweight.sample(1174,replace = False)\n",
    "shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-02T13:18:01.308908Z"
    }
   },
   "outputs": [],
   "source": [
    "shuffled_weights = shuffled['Birth Weight']\n",
    "type(shuffled_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "shuffled_weights"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-02T13:18:01.309449Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-02T13:18:01.309957Z"
    }
   },
   "outputs": [],
   "source": [
    "original_and_shuffled= smoking_and_birthweight.assign(shuffled_weights=shuffled_weights.values )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-02T13:18:01.310456Z"
    }
   },
   "outputs": [],
   "source": [
    "original_and_shuffled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each mother now has a random birth weight assigned to her. If the null hypothesis is true, all these random arrangements should be equally likely. See how different the average weights are in the two randomly selected groups. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-02T13:18:01.310962Z"
    }
   },
   "outputs": [],
   "source": [
    "all_group_means= original_and_shuffled.groupby('Maternal Smoker').mean()\n",
    "all_group_means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The averages of the two randomly selected groups are quite a bit closer than the averages of the two original groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-02T13:18:01.311516Z"
    }
   },
   "outputs": [],
   "source": [
    "difference = all_group_means['shuffled_weights'][0]- all_group_means['shuffled_weights'][1]\n",
    "difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### But could a different shuffle have resulted in a larger difference between the group average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a sense of the variability, simulate the difference many times. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### One simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-02T13:18:01.312004Z"
    }
   },
   "outputs": [],
   "source": [
    "smoking_and_birthweight = baby[['Maternal Smoker', 'Birth Weight']]\n",
    "shuffled = smoking_and_birthweight.sample(1174,replace = False)\n",
    "shuffled_weights = shuffled['Birth Weight']\n",
    "original_and_shuffled = smoking_and_birthweight.assign(shuffled_weights=shuffled_weights.values )\n",
    "all_group_means= original_and_shuffled.groupby('Maternal Smoker').mean()\n",
    "difference = all_group_means['shuffled_weights'][0]- all_group_means['shuffled_weights'][1]\n",
    "difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Permutation Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests based on random permutations of the data are called permutation tests. Simulate the test statistic – the\n",
    "difference between the averages of the two groups – many times and collect the differences in an array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-02T13:18:01.312587Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import array\n",
    "differences = np.zeros(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-02T13:18:01.313183Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in np.arange(5000):\n",
    "    smoking_and_birthweight = baby[['Maternal Smoker', 'Birth Weight']]\n",
    "    shuffled = smoking_and_birthweight.sample(1174,replace = False)\n",
    "    shuffled_weights = shuffled['Birth Weight']\n",
    "    original_and_shuffled = smoking_and_birthweight.assign(shuffled_weights=shuffled_weights.values )\n",
    "    all_group_means= original_and_shuffled.groupby('Maternal Smoker').mean()\n",
    "    difference = all_group_means['shuffled_weights'][0]- all_group_means['shuffled_weights'][1]\n",
    "    differences[i] = difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-02T13:18:01.313667Z"
    }
   },
   "outputs": [],
   "source": [
    "differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-02T13:18:01.314225Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-02T13:18:01.314829Z"
    }
   },
   "outputs": [],
   "source": [
    "differences_df = pd.DataFrame(differences)\n",
    "differences_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-02T13:18:01.315717Z"
    }
   },
   "outputs": [],
   "source": [
    "differences_df.hist(bins = np.arange(-5,5,0.5))\n",
    "plt.title('Prediction Under Null Hypotheses');\n",
    "plt.xlabel('Differences between Group Averages',fontsize=15)\n",
    "plt.ylabel('Units',fontsize=15);\n",
    "print('Observed Difference:', observed_difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the distribution is centered around 0. This makes sense, because under the null hypothesis the two groups should have roughly the same average. Therefore the difference between the group averages should be around 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The observed difference in the original sample is about -9.27 ounces, which doesn't even appear on the horizontal scale of the histogram. The observed value of the statistic and the predicted behavior of the statistic under the null hypothesis are inconsistent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The conclusion of the test is that the data support the alternative more than they support the null. The average birth weight of babies born to mothers who smoke is less than the average birth weight of babies born to non-smokers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to compute an empirical P-value, remember that low values of the statistic favor\n",
    "the alternative hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-02T13:18:01.316814Z"
    }
   },
   "outputs": [],
   "source": [
    "np.count_nonzero(differences <= observed_difference)/differences.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The empirical P-value is 0, meaning that none of the 5,000 observed samples resulted in a difference of -9.27 or lower. This is an approximation; the exact chance of getting a difference in that range is not 0 but it is vanishingly small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assignment - Write a Function to Simulate the Differences Under the Null Hypothesis and test whether there was any difference in the ages of the smoking and non-smoking mothers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
