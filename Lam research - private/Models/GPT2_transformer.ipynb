{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-23T03:46:31.783668Z",
     "start_time": "2023-12-23T03:46:30.811835Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel,GPT2Tokenizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "model_name = \"gpt2-large\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T03:46:52.578901Z",
     "start_time": "2023-12-23T03:46:31.784184Z"
    }
   },
   "id": "4840f2a2874c757c"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "GPT2LMHeadModel(\n  (transformer): GPT2Model(\n    (wte): Embedding(50257, 1280)\n    (wpe): Embedding(1024, 1280)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0-35): 36 x GPT2Block(\n        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=1280, out_features=50257, bias=False)\n)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T03:46:52.587726Z",
     "start_time": "2023-12-23T03:46:52.572718Z"
    }
   },
   "id": "690c2304592c63f3"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 774030080\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of parameters:\", model.num_parameters())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T03:46:52.589454Z",
     "start_time": "2023-12-23T03:46:52.583647Z"
    }
   },
   "id": "98b1ab353ca2e6ad"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def generate_text(prompt, max_length=100, temperature=0.1, top_k=50):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        max_length=max_length,\n",
    "        temperature=temperature,\n",
    "        top_k=top_k,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        do_sample=True\n",
    "    )\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return generated_text"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T03:46:52.590633Z",
     "start_time": "2023-12-23T03:46:52.584229Z"
    }
   },
   "id": "45801542dd6387c8"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cities in US are San Fransico, New York, Los Angeles, Chicago, Miami, Dallas, Houston, Atlanta, Boston, Washington DC, Philadelphia, San Diego, San Francisco, Seattle\n"
     ]
    }
   ],
   "source": [
    "prompt = \"The cities in US are San Fransico,\"\n",
    "generated_text = generate_text(prompt, max_length=40)\n",
    "\n",
    "# Print the generated text\n",
    "print(generated_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T03:46:58.209178Z",
     "start_time": "2023-12-23T03:46:52.585050Z"
    }
   },
   "id": "7fb6d0c7c716e995"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of India is located in the state of Uttar Pradesh, which is known for its rich culture and history. The city is also known for its beautiful temples and monuments.\n",
      "\n",
      "The city is also known for its beautiful temples and monuments. The\n"
     ]
    }
   ],
   "source": [
    "prompt = \"The capital of India is located in\"\n",
    "generated_text = generate_text(prompt, max_length=50)\n",
    "\n",
    "# Print the generated text\n",
    "print(generated_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T03:48:10.111543Z",
     "start_time": "2023-12-23T03:48:04.548746Z"
    }
   },
   "id": "11844a04712c3b7a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "interact_model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec2b7607dc13e8c5"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e350ec107bcc41ddaf650a261e40a66e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d94e19fd32c444be938d5e4df337ccd7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4afdb13d9aa34eba81d9719583158153"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "61dfa5088daf4803b105cb809e6bc0f5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c19fe5c45f7641ca91329d5d82c539c7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "992c7d3650f54d8a822353eb6045c298"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T03:40:02.231490Z",
     "start_time": "2023-12-23T03:33:03.620518Z"
    }
   },
   "id": "1c7b6a9cb606d289"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "60506624"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_parameters()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T03:41:38.641712Z",
     "start_time": "2023-12-23T03:41:38.635611Z"
    }
   },
   "id": "b072eedd8e4dd663"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "<bound method Module.eval of T5ForConditionalGeneration(\n  (shared): Embedding(32128, 512)\n  (encoder): T5Stack(\n    (embed_tokens): Embedding(32128, 512)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n              (relative_attention_bias): Embedding(32, 8)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-5): 5 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (decoder): T5Stack(\n    (embed_tokens): Embedding(32128, 512)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n              (relative_attention_bias): Embedding(32, 8)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-5): 5 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n)>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T03:43:13.832596Z",
     "start_time": "2023-12-23T03:43:13.822963Z"
    }
   },
   "id": "556779f07e7e747a"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def generate_text(prompt, max_length=100, temperature=0.1, top_k=50):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        max_length=max_length,\n",
    "        temperature=temperature,\n",
    "        top_k=top_k,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        do_sample=True\n",
    "    )\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return generated_text"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T03:45:08.462186Z",
     "start_time": "2023-12-23T03:45:08.457701Z"
    }
   },
   "id": "284ed0c2ce39866d"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pouss you sing me a poem\n"
     ]
    }
   ],
   "source": [
    "prompt = (\"Can you sing me a poem\")\n",
    "generated_text = generate_text(prompt, max_length=40)\n",
    "print(generated_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T03:46:21.468891Z",
     "start_time": "2023-12-23T03:46:21.334862Z"
    }
   },
   "id": "e0a6401c19790644"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2Config\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Load pre-trained GPT-2 model and tokenizer\n",
    "model_name = \"gpt2-large\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T11:32:30.108557Z",
     "start_time": "2023-12-24T11:32:11.669826Z"
    }
   },
   "id": "fc5705c795cb4c1f"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "# Load your tabular data (replace with your own)\n",
    "data = {\n",
    "    \"Name\": [\"John\", \"Alice\", \"Bob\"],\n",
    "    \"Age\": [25, 30, 22],\n",
    "    \"City\": [\"New York\", \"San Francisco\", \"Los Angeles\"],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert tabular data to text\n",
    "text_data = []\n",
    "for index, row in df.iterrows():\n",
    "    row_text = \" \".join([f\"[{col}]: {str(row[col])}\" for col in df.columns])\n",
    "    text_data.append(row_text)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T11:30:38.473109Z",
     "start_time": "2023-12-24T11:30:36.132229Z"
    }
   },
   "id": "830c4e5589e5a405"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "['[Name]: John [Age]: 25 [City]: New York',\n '[Name]: Alice [Age]: 30 [City]: San Francisco',\n '[Name]: Bob [Age]: 22 [City]: Los Angeles']"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T11:30:41.421971Z",
     "start_time": "2023-12-24T11:30:41.383376Z"
    }
   },
   "id": "60633524b5ef71d8"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "tokenized_data = [tokenizer.encode(row, return_tensors=\"pt\") for row in text_data]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T11:33:13.047485Z",
     "start_time": "2023-12-24T11:33:13.025068Z"
    }
   },
   "id": "5da5ee33fbbe576a"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "[tensor([[   58,  5376,  5974,  1757,   685, 23396,  5974,  1679,   685, 14941,\n           5974,   968,  1971]]),\n tensor([[   58,  5376,  5974, 14862,   685, 23396,  5974,  1542,   685, 14941,\n           5974,  2986,  6033]]),\n tensor([[   58,  5376,  5974,  5811,   685, 23396,  5974,  2534,   685, 14941,\n           5974,  5401,  5652]])]"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T11:33:16.767480Z",
     "start_time": "2023-12-24T11:33:16.755697Z"
    }
   },
   "id": "9c3b3f49ece9f72f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Convert tabular data to text\n",
    "text_data = []\n",
    "for index, row in df.iterrows():\n",
    "    row_text = \" \".join([f\"[{col}]: {str(row[col])}\" for col in df.columns])\n",
    "    text_data.append(row_text)\n",
    "\n",
    "# Tokenize the tabular data\n",
    "tokenized_data = [tokenizer.encode(row, return_tensors=\"pt\") for row in text_data]\n",
    "\n",
    "# DataLoader for training\n",
    "dataloader = DataLoader(tokenized_data, batch_size=2, shuffle=True)\n",
    "\n",
    "# Example fine-tuning function\n",
    "def fine_tune_gpt2(model_name, dataloader, output_dir):\n",
    "    # Load GPT-2 model\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "    \n",
    "    # Fine-tuning setup...\n",
    "    # (You can use the provided fine-tuning function or customize it based on your specific needs)\n",
    "\n",
    "    # Example training loop\n",
    "    for epoch in range(5):\n",
    "        for inputs in dataloader:\n",
    "            model.train()\n",
    "            # Your training code here...\n",
    "            # (This is where you update the model with your training data)\n",
    "\n",
    "    # Save the fine-tuned model\n",
    "    model.save_pretrained(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "# Example usage\n",
    "fine_tune_gpt2(\"gpt2-large\", dataloader, \"downloads\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-12-24T11:51:31.121107Z"
    }
   },
   "id": "6fd533397229e012"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d3cfbf8de0eb7a7c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
